8.3分布式计算框架MapReduce

1. MapReduce基本概念

Mapeduce是一个分布式运算程序的编程框架，是用户开发“基于hadoop的数据分析应用”的核心框架。
  Mapeduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个 hadoop 集群上。

2. Map Reduce优缺点
   (1) 优点:
   (a)MapReduce 易于编程。
    它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量廉价的PC机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得MapReduce编程变得非常流行。

(b)良好的扩展性。
    当你的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。

(c )高容错性。
    MapReduce设计的初衷就是使程序能够部署在廉价的PC机器上，这就要求它具有很高的容错性。比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由 Hadoop内部完成的。

(d)适合PB级以上海量数据的离线处理。
    这里加红字体离线处理，说明它适合离线处理而不适合在线处理。比如像毫秒级别的返回一个结果，MapReduce很难做到。

(2) 缺点:
    MapReduce不擅长做实时计算、流式计算、DAG（有向图）计算。

(a)实时计算。
MapReduce无法像Mysql一样，在毫秒或者秒级内返回结果。

(b)流式计算。
流式计算的输入数据是动态的，而Map Reduce的输入数据集是静态的，不能动态变化。这是因为MapReduce自身的设计特点决定了数据源必须是静态的。

(c )DAG（有向图）计算。多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce并不是不能做，而是使用后，每个MapReduce作业的输出结果都会写入到磁盘，会造成大量的磁盘IO，导致性能非常的低下。

8.3.1 MapReduce编程模型

1. MapReduce编程模型简介

​    MapReduce由两个阶段组成：Map和Reduce，用户只需要编写map()和reduce()两个函数，即可完成简单的分布式程序的设计。

2. 分类

​    （1）MapReduce简单模型

​    （2）MapReduce复杂模型

3. MapReduce 编程实例

   实现WorldCount的伪代码如下：

   mapper(String key,String value)                //key: 偏移量   value: 字符串内容

   {

   ​       words=SplitInTokens(value);             //切分字符串

   ​       for each word w in words                 //对字符串中的每一个word

   ​                  Emit(w,1);                                  //输出 word ,1

   }

   reducer(string key,value_list)                 //key:单词：value_list:值列表

   {

   ​        int sum=0;

   ​        for each value in value_list             //对列表中的每一个值

   ​                   sum +=value;                        //加到变量sum中

   ​        Emit(key,sum);                                //输出key,sum

   }

8.3.2 MapReduce 数据流

​       1.首先数据会按照TextInputFormat按照特定的文本输入格式被处理成两个InputSplit,当然一般是这样，每增加一个块分区（Block,简单的说是几个文件我是这么理解的）就会加一个InputSplit。

　　2.将InputSplit分割的内容输入到相应的Map中（map会读取inputSplit指定位置的数据），有几个InputSplit就有几个Map

　　3.在Map里面进行处理的时候首先会将分割的内容放进去，并转换成方便处理的格式然后写入到本地磁盘中，简单点说就是将标准的输入格式，处理成标准的输出格式（我的理解是，处理方式都是死的，是按照一定的格式才能进行处理，包括成为key value对，也是一种格式。只有转换成特定的格式，才能进行批处理。否则容易出问题）。然后进行Map处理成key/value 。　　

　　4.在Map处理成规定的key/value后，数据进入shuffle，里面会自动进行归类。比如说我读入数据是(key,value)就会处理称为 (key,value_list)，将相同的key进行合并，值组成一个列表。

　　5.然后传入reduce处理，在reduce中会将数据进行整合，一般可以在这里将不同文件的数据进行笛卡尔积，说是这么说，其实就是把数据对应的拿出来，按照key相同值处理的方式进行遍历处理。

8.3.3 MapReduce 任务运行流程

1. MRv2 基本组成

MRv2最基本的设计思想是将JobTracker的两个主要功能，即资源管理和作业调度/监控分成两个独立的进程。在该解决方案中包含两个组件：全局的ResourceManager（RM）和与每个应用相关的ApplicationMaster（AM）。

2. Yarn基本组成

   YARN主要由ResourceManager、NodeManager、ApplicationMaster和[Container](http://lib.csdn.net/base/4)等几个组件构成。

（1）ResourceManager（RM）

RM是一个全局的资源管理器，负责整个系统的资源管理和分配。它主要由两个组件构成：调度器（Scheduler）和应用程序管理器（Applications Manager，ASM）。

调度器（Scheduler）仅负责分配资源，不负责程序的监控或者跟踪应用程序的执行状态，也不负责重新启动因应用执行失败或者硬件故障而产生的失败任务（这些均交由应用程序相关的ApplicationMaster）。

调度器仅根据各个应用程序的资源需求进行资源分配，而资源分配单位用一个抽象概念“资源容器”（Resource Container，简称Container）表示，Container是一个动态资源分配单位，它将内存、CPU、磁盘、网络等资源封装在一起，从而限定每个任务使用的资源量。此外，该调度器是一个可插拔的组件，用户可根据自己的需要设计新的调度器，YARN提供了多种直接可用的调度器，比如Fair Scheduler和Capacity Scheduler等。

（2）ApplicationMaster（AM）

用户提交的每一个应用程序都包括一个AM，AM主要有以下功能：

 a.与RM协调器协商以获取资源（用Container表示）；

 b.将得到的任务进一步分配给内部任务；

 c.与NM通信以启动/停止任务；

  d.监控任务的状态，并在任务失败时重新为任务申请资源以重启任务。

当前YARN自带了两个AM实现，一个是用于演示AM编写方法的实例程序distributedshell，它可以申请一定数目的Container以并行运行一个Shell命令或者Shell脚本；另一个是运行MapReduce应用程序的AM—MRAppMaster

（3）NodeManager(NM)

  NM是每个节点上的资源和任务管理器，它会定时向RM汇报本节点的资源使用情况和各个Container的运行状态，它还接收并处理来自AM的Container启动/停止等请求

（4）Container
Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等，当AM向RM申请资源时，RM为AM返回的资源便是用Container表示的。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。

3. 任务流程

   （1）client 向 ResourceManager提交任务。

   （2）ResourceManager分配该任务的第一个container，并通知相应的NodeManager启动MRAppMaster。
   （3）NodeManager接收命令后，开辟一个container资源空间，并在container中启动相应的MRAppMaster。
   （4）MRAppMaster启动之后，第一步会向 ResourceManager注册，这样用户可以直接通过MRAppMaster监控任务的运行状态；之后则直接由MRAppMaster调度任务运行，重复5)～
   8)，直到任务结束。
   （5）MRAppMaster以轮询的方式向ResourceManager申请任务运行所需的资源。
   （6）一旦ResourceManager配给了资源，MRAppMaster便会与相应的NodeManager通信，让它划分Container并启动相应的任务(MapTask或ReduceTask)。
   （7） NodeManager准备好运行环境，启动任务。
   （8）各任务运行，并定时通过RPC协议向MRAppMaster汇报自己的运行状态和进度。MRAppMaster也会实时地监控任务的运行，当发现某个Task假死或失败时，便杀死它重新启动任务。
   （9）任务完成，MRAppMaster向ResourceManager通信，注销并关闭自己。

